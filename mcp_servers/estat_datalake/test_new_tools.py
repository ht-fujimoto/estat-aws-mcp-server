#!/usr/bin/env python3
"""
æ–°ã—ãè¿½åŠ ã—ãŸMCPãƒ„ãƒ¼ãƒ«ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ãƒ†ã‚¹ãƒˆå¯¾è±¡:
- fetch_dataset_filtered
- fetch_large_dataset_complete
- analyze_with_athena
"""

import json
import subprocess
import sys


def test_mcp_tool(tool_name: str, arguments: dict):
    """MCPãƒ„ãƒ¼ãƒ«ã‚’ãƒ†ã‚¹ãƒˆ"""
    print(f"\n{'='*60}")
    print(f"Testing: {tool_name}")
    print(f"Arguments: {json.dumps(arguments, ensure_ascii=False, indent=2)}")
    print(f"{'='*60}\n")
    
    # tools/call ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ä½œæˆ
    request = {
        "jsonrpc": "2.0",
        "id": 1,
        "method": "tools/call",
        "params": {
            "name": tool_name,
            "arguments": arguments
        }
    }
    
    # MCPã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã—ã¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
    try:
        process = subprocess.Popen(
            ["python3", "mcp_servers/estat_datalake/server.py"],
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
        stdout, stderr = process.communicate(
            input=json.dumps(request) + "\n",
            timeout=120
        )
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è§£æ
        lines = stdout.strip().split('\n')
        for line in lines:
            if line.strip():
                try:
                    response = json.loads(line)
                    if "result" in response:
                        result_text = response["result"]["content"][0]["text"]
                        result = json.loads(result_text)
                        
                        print("âœ… Success!")
                        print(f"Result: {json.dumps(result, ensure_ascii=False, indent=2)}")
                        return result
                    elif "error" in response:
                        print(f"âŒ Error: {response['error']}")
                        return None
                except json.JSONDecodeError:
                    continue
        
        if stderr:
            print(f"âš ï¸  Stderr: {stderr}")
        
        return None
        
    except subprocess.TimeoutExpired:
        print("âŒ Timeout: ãƒ†ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ")
        process.kill()
        return None
    except Exception as e:
        print(f"âŒ Exception: {e}")
        return None


def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª E-stat Data Lake MCP Server - æ–°ãƒ„ãƒ¼ãƒ«ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    # ãƒ†ã‚¹ãƒˆ1: fetch_dataset_filtered
    print("\nğŸ“‹ Test 1: fetch_dataset_filtered")
    print("å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ•ã‚£ãƒ«ã‚¿ä»˜ãã§å–å¾—")
    test_mcp_tool("fetch_dataset_filtered", {
        "dataset_id": "0003410379",  # çµŒæ¸ˆã‚»ãƒ³ã‚µã‚¹
        "filters": {
            "area": "13000",  # æ±äº¬éƒ½
            "time": "2021"    # 2021å¹´
        },
        "save_to_s3": False  # ãƒ†ã‚¹ãƒˆãªã®ã§S3ä¿å­˜ã¯ã‚¹ã‚­ãƒƒãƒ—
    })
    
    # ãƒ†ã‚¹ãƒˆ2: fetch_large_dataset_complete
    print("\nğŸ“‹ Test 2: fetch_large_dataset_complete")
    print("å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’åˆ†å‰²å–å¾—ï¼ˆãƒ†ã‚¹ãƒˆç”¨ã«æœ€å¤§10ä¸‡ä»¶ï¼‰")
    test_mcp_tool("fetch_large_dataset_complete", {
        "dataset_id": "0003410379",
        "chunk_size": 50000,
        "max_records": 100000,
        "save_to_s3": False  # ãƒ†ã‚¹ãƒˆãªã®ã§S3ä¿å­˜ã¯ã‚¹ã‚­ãƒƒãƒ—
    })
    
    # ãƒ†ã‚¹ãƒˆ3: analyze_with_athena (basic)
    print("\nğŸ“‹ Test 3: analyze_with_athena (basic)")
    print("åŸºæœ¬çµ±è¨ˆåˆ†æã‚’å®Ÿè¡Œ")
    test_mcp_tool("analyze_with_athena", {
        "table_name": "population_data",
        "analysis_type": "basic"
    })
    
    # ãƒ†ã‚¹ãƒˆ4: analyze_with_athena (advanced)
    print("\nğŸ“‹ Test 4: analyze_with_athena (advanced)")
    print("é«˜åº¦ãªçµ±è¨ˆåˆ†æã‚’å®Ÿè¡Œ")
    test_mcp_tool("analyze_with_athena", {
        "table_name": "population_data",
        "analysis_type": "advanced"
    })
    
    # ãƒ†ã‚¹ãƒˆ5: analyze_with_athena (custom)
    print("\nğŸ“‹ Test 5: analyze_with_athena (custom)")
    print("ã‚«ã‚¹ã‚¿ãƒ ã‚¯ã‚¨ãƒªã§åˆ†æã‚’å®Ÿè¡Œ")
    test_mcp_tool("analyze_with_athena", {
        "table_name": "population_data",
        "analysis_type": "custom",
        "custom_query": """
            SELECT year, COUNT(*) as count
            FROM estat_iceberg_db.population_data
            GROUP BY year
            ORDER BY year DESC
            LIMIT 10
        """
    })
    
    print("\n" + "=" * 60)
    print("âœ… å…¨ãƒ†ã‚¹ãƒˆå®Œäº†")


if __name__ == "__main__":
    main()
